loss,grad_norm,learning_rate,epoch,step,train_runtime,train_samples_per_second,train_steps_per_second,total_flos,train_loss
2.4254,1.128659963607788,9.423076923076923e-06,0.06430868167202572,10,,,,,
2.5052,2.0755491256713867,8.782051282051283e-06,0.12861736334405144,20,,,,,
2.5749,1.9803838729858398,8.141025641025641e-06,0.19292604501607716,30,,,,,
2.4527,2.1895973682403564,7.500000000000001e-06,0.2572347266881029,40,,,,,
2.4366,1.7413259744644165,6.858974358974359e-06,0.3215434083601286,50,,,,,
2.4603,2.0217058658599854,6.217948717948718e-06,0.3858520900321543,60,,,,,
2.44,1.9465410709381104,5.576923076923077e-06,0.45016077170418006,70,,,,,
2.4483,2.1387972831726074,4.935897435897436e-06,0.5144694533762058,80,,,,,
2.401,1.7356103658676147,4.294871794871795e-06,0.5787781350482315,90,,,,,
2.3525,2.254467248916626,3.653846153846154e-06,0.6430868167202572,100,,,,,
2.5458,2.6548988819122314,3.012820512820513e-06,0.707395498392283,110,,,,,
2.3157,2.4823544025421143,2.371794871794872e-06,0.7717041800643086,120,,,,,
2.2336,2.1072070598602295,1.7307692307692308e-06,0.8360128617363344,130,,,,,
2.3876,2.2982864379882812,1.0897435897435899e-06,0.9003215434083601,140,,,,,
2.3801,2.2069950103759766,4.4871794871794876e-07,0.9646302250803859,150,,,,,
,,,1.0,156,3765.6818,0.083,0.041,930142991941632.0,2.4168757781004295
